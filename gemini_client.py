import os
from typing import List, Dict, Any, Optional
from langchain.llms.base import LLM
from langchain.callbacks.manager import CallbackManagerForLLMRun
from config import Config

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸ è­¦å‘Š: google-generativeai åº“æœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
    print("è¯·è¿è¡Œ: pip install google-generativeai")


class GeminiLLM(LLM):
    """Gemini APIçš„LangChain LLMåŒ…è£…å™¨"""

    api_key: str = Config.GEMINI_API_KEY
    model: str = Config.DEFAULT_MODEL
    max_tokens: int = Config.MAX_TOKENS
    temperature: float = Config.TEMPERATURE
    gemini_model: Any = None
    generation_config: Any = None

    class Config:
        """å…è®¸ä»»æ„ç±»å‹çš„å­—æ®µ"""
        arbitrary_types_allowed = True
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        if GEMINI_AVAILABLE:
            # é…ç½®Gemini API
            genai.configure(api_key=self.api_key)

            # åˆ›å»ºç”Ÿæˆé…ç½®
            self.generation_config = {
                'max_output_tokens': self.max_tokens,
                'temperature': self.temperature,
            }

            # ç®€åŒ–åˆå§‹åŒ–ï¼Œé¿å…ç½‘ç»œè°ƒç”¨
            try:
                # éªŒè¯æ¨¡å‹åç§°æ ¼å¼
                model_name = self.model if not self.model.startswith("models/") else self.model.replace("models/", "")
                self.gemini_model = model_name  # å­˜å‚¨æ¨¡å‹åç§°
                print(f"âœ… Geminiæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {model_name}")

            except Exception as e:
                raise Exception(f"æ— æ³•åˆå§‹åŒ–Geminiæ¨¡å‹: {str(e)}")
        else:
            # æ¨¡æ‹Ÿæ¨¡å¼
            self.gemini_model = None
            print(f"ğŸ”§ æ¨¡æ‹Ÿæ¨¡å¼: ä½¿ç”¨æ¨¡å‹ {self.model}")
    
    @property
    def _llm_type(self) -> str:
        return "gemini"
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        """è°ƒç”¨Gemini API"""
        if not GEMINI_AVAILABLE:
            # æ¨¡æ‹Ÿæ¨¡å¼å“åº” - ç¬¦åˆReActæ ¼å¼
            if "ä½ å¥½" in prompt or "hello" in prompt.lower():
                return """Thought: ç”¨æˆ·åœ¨é—®å€™æˆ‘ï¼Œæˆ‘åº”è¯¥å‹å¥½åœ°å›åº”ã€‚
Final Answer: ä½ å¥½ï¼æˆ‘æ˜¯åŸºäºGemini APIçš„æ™ºèƒ½ä½“åŠ©æ‰‹ã€‚ç›®å‰æ­£åœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹è¿è¡Œï¼Œè¦ä½¿ç”¨çœŸå®çš„Gemini APIï¼Œè¯·å®‰è£…google-generativeaiåº“å¹¶é…ç½®APIå¯†é’¥ã€‚æˆ‘å¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œè®¡ç®—ã€æœç´¢ã€æ–‡ä»¶æ“ä½œç­‰ä»»åŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"""
            else:
                return f"""Thought: æˆ‘éœ€è¦å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä½†ç›®å‰åœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹è¿è¡Œã€‚
Final Answer: æŠ±æ­‰ï¼Œæˆ‘ç›®å‰åœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹è¿è¡Œã€‚è¦ä½¿ç”¨çœŸå®çš„Gemini APIåŠŸèƒ½ï¼Œè¯·ï¼š
1. å®‰è£…ä¾èµ–: pip install google-generativeai
2. é…ç½®APIå¯†é’¥: GEMINI_API_KEY=your_key
3. é‡å¯ç¨‹åº

æ‚¨çš„é—®é¢˜æ˜¯: {prompt[:100]}{'...' if len(prompt) > 100 else ''}
å½“å‰ä½¿ç”¨æ¨¡å‹: {self.model}"""

        try:
            # ä½¿ç”¨æ–°ç‰ˆAPIç”Ÿæˆå“åº”
            model_name = self.model if not self.model.startswith("models/") else self.model.replace("models/", "")

            # åˆ›å»ºç”Ÿæˆæ¨¡å‹å®ä¾‹
            model = genai.GenerativeModel(model_name)

            # ç”Ÿæˆå“åº”
            response = model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=self.max_tokens,
                    temperature=self.temperature,
                )
            )

            # è¿”å›ç”Ÿæˆçš„æ–‡æœ¬
            if response and response.text:
                return response.text
            else:
                return "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå“åº”ã€‚è¯·é‡è¯•ã€‚"

        except Exception as e:
            # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œæä¾›ä¸€ä¸ªæ™ºèƒ½çš„æ¨¡æ‹Ÿå“åº”
            error_msg = str(e)
            if "404" in error_msg or "not found" in error_msg.lower():
                # æ¨¡å‹ä¸å­˜åœ¨ï¼Œæä¾›æœ‰ç”¨çš„æ¨¡æ‹Ÿå“åº”
                return self._generate_fallback_response(prompt)
            else:
                raise Exception(f"Gemini APIè°ƒç”¨å¤±è´¥: {str(e)}")
    
    def _generate_fallback_response(self, prompt: str) -> str:
        """ç”Ÿæˆæ™ºèƒ½çš„å›é€€å“åº”"""
        import datetime
        import re

        # åˆ†æç”¨æˆ·è¾“å…¥ï¼Œæä¾›ç›¸åº”çš„å›ç­”
        prompt_lower = prompt.lower()

        # æ—¶é—´ç›¸å…³é—®é¢˜
        if any(word in prompt_lower for word in ['ä»Šå¤©', 'ç°åœ¨', 'æ—¶é—´', 'æ—¥æœŸ', 'å‡ å·', 'today', 'now', 'time', 'date']):
            now = datetime.datetime.now()
            return f"""Thought: ç”¨æˆ·è¯¢é—®æ—¶é—´ç›¸å…³ä¿¡æ¯ï¼Œæˆ‘éœ€è¦æä¾›å½“å‰çš„æ—¥æœŸå’Œæ—¶é—´ã€‚
Final Answer: ä»Šå¤©æ˜¯{now.strftime('%Yå¹´%mæœˆ%dæ—¥')}ï¼Œç°åœ¨æ˜¯{now.strftime('%H:%M')}ã€‚

æ³¨æ„ï¼šæˆ‘ç›®å‰ä½¿ç”¨çš„æ˜¯ä¸´æ—¶å“åº”æ¨¡å¼ï¼Œå› ä¸ºGemini APIæ¨¡å‹ä¸å¯ç”¨ã€‚è¦è·å¾—å®Œæ•´åŠŸèƒ½ï¼Œè¯·ï¼š
1. å‡çº§Pythonåˆ°3.9+ç‰ˆæœ¬
2. å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„google-generativeaiåº“
3. ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸"""

        # é—®å€™è¯­
        elif any(word in prompt_lower for word in ['ä½ å¥½', 'hello', 'hi', 'æ‚¨å¥½']):
            return """Thought: ç”¨æˆ·åœ¨é—®å€™æˆ‘ï¼Œæˆ‘åº”è¯¥å‹å¥½åœ°å›åº”å¹¶è¯´æ˜å½“å‰çŠ¶æ€ã€‚
Final Answer: ä½ å¥½ï¼æˆ‘æ˜¯åŸºäºGemini APIçš„æ™ºèƒ½åŠ©æ‰‹ã€‚

âš ï¸ å½“å‰çŠ¶æ€æé†’ï¼š
- æˆ‘æ­£åœ¨ä½¿ç”¨ä¸´æ—¶å“åº”æ¨¡å¼
- Gemini APIæ¨¡å‹æš‚æ—¶ä¸å¯ç”¨ï¼ˆå¯èƒ½æ˜¯ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼‰
- è¦è·å¾—å®Œæ•´çš„AIåŠŸèƒ½ï¼Œéœ€è¦è§£å†³APIè¿æ¥é—®é¢˜

æˆ‘ä»ç„¶å¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œä¸€äº›åŸºæœ¬çš„ä»»åŠ¡å’Œå›ç­”ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"""

        # è®¡ç®—ç›¸å…³
        elif any(word in prompt_lower for word in ['è®¡ç®—', 'ç®—', '+', '-', '*', '/', 'calculate']):
            # å°è¯•ç®€å•çš„æ•°å­¦è®¡ç®—
            try:
                # æå–æ•°å­—å’Œè¿ç®—ç¬¦
                numbers = re.findall(r'\d+(?:\.\d+)?', prompt)
                if len(numbers) >= 2:
                    # ç®€å•çš„åŠ å‡ä¹˜é™¤
                    if '+' in prompt:
                        result = float(numbers[0]) + float(numbers[1])
                        return f"""Thought: ç”¨æˆ·è¦æ±‚è®¡ç®— {numbers[0]} + {numbers[1]}ã€‚
Final Answer: {numbers[0]} + {numbers[1]} = {result}

æ³¨æ„ï¼šè¿™æ˜¯åŸºæœ¬è®¡ç®—åŠŸèƒ½ã€‚å®Œæ•´çš„AIè®¡ç®—èƒ½åŠ›éœ€è¦Gemini APIæ­£å¸¸å·¥ä½œã€‚"""
                    elif '*' in prompt:
                        result = float(numbers[0]) * float(numbers[1])
                        return f"""Thought: ç”¨æˆ·è¦æ±‚è®¡ç®— {numbers[0]} Ã— {numbers[1]}ã€‚
Final Answer: {numbers[0]} Ã— {numbers[1]} = {result}

æ³¨æ„ï¼šè¿™æ˜¯åŸºæœ¬è®¡ç®—åŠŸèƒ½ã€‚å®Œæ•´çš„AIè®¡ç®—èƒ½åŠ›éœ€è¦Gemini APIæ­£å¸¸å·¥ä½œã€‚"""
            except:
                pass

            return """Thought: ç”¨æˆ·è¯¢é—®è®¡ç®—ç›¸å…³é—®é¢˜ï¼Œä½†æˆ‘æ— æ³•è§£æå…·ä½“çš„è®¡ç®—å†…å®¹ã€‚
Final Answer: æˆ‘å¯ä»¥å¸®æ‚¨è¿›è¡ŒåŸºæœ¬çš„æ•°å­¦è®¡ç®—ï¼Œä½†ç›®å‰å¤„äºä¸´æ—¶æ¨¡å¼ã€‚è¯·æä¾›å…·ä½“çš„è®¡ç®—è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ï¼š"è®¡ç®— 25 * 4 + 10"ã€‚

è¦è·å¾—å®Œæ•´çš„è®¡ç®—å’Œåˆ†æèƒ½åŠ›ï¼Œéœ€è¦è§£å†³Gemini APIè¿æ¥é—®é¢˜ã€‚"""

        # é»˜è®¤å“åº”
        else:
            return f"""Thought: ç”¨æˆ·æå‡ºäº†é—®é¢˜ï¼Œä½†æˆ‘ç›®å‰å¤„äºä¸´æ—¶å“åº”æ¨¡å¼ã€‚
Final Answer: æ„Ÿè°¢æ‚¨çš„é—®é¢˜ã€‚æˆ‘ç›®å‰å¤„äºä¸´æ—¶å“åº”æ¨¡å¼ï¼Œå› ä¸ºGemini APIæš‚æ—¶ä¸å¯ç”¨ã€‚

æ‚¨çš„é—®é¢˜æ˜¯ï¼š{prompt[:100]}{'...' if len(prompt) > 100 else ''}

ğŸ”§ æŠ€æœ¯çŠ¶æ€ï¼š
- å½“å‰Pythonç‰ˆæœ¬ï¼š3.8.8
- éœ€è¦Pythonç‰ˆæœ¬ï¼š3.9+
- google-generativeaiç‰ˆæœ¬ï¼š0.1.0rc1ï¼ˆæ—§ç‰ˆæœ¬ï¼‰
- é—®é¢˜ï¼šæ—§ç‰ˆæœ¬APIä¸æ”¯æŒç°ä»£Geminiæ¨¡å‹

ğŸ’¡ å»ºè®®è§£å†³æ–¹æ¡ˆï¼š
1. å‡çº§Pythonç¯å¢ƒåˆ°3.9+
2. å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„google-generativeaiåº“
3. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œä»£ç†è®¾ç½®

åœ¨è§£å†³è¿™äº›é—®é¢˜ä¹‹å‰ï¼Œæˆ‘åªèƒ½æä¾›åŸºæœ¬çš„å“åº”ã€‚"""

    @property
    def _identifying_params(self) -> Dict[str, Any]:
        """è¿”å›æ ‡è¯†å‚æ•°"""
        return {
            "model": self.model,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature
        }
